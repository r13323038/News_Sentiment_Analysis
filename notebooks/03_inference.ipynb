{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6894fa5b",
   "metadata": {},
   "source": [
    "# Part 2 Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb9e0d5",
   "metadata": {},
   "source": [
    "## 1. Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2654d0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ æ‰¾åˆ° 32 å€‹ CSV æª”æ¡ˆ\n",
      "âœ… åˆä½µå®Œæˆï¼ç¸½å…±æœ‰ 3196 ç­†è³‡æ–™\n",
      "ğŸ§¹ å»é™¤é‡è¤‡å¾Œå‰©é¤˜: 2128 ç­† (åˆªé™¤äº† 1068 ç­†)\n",
      "         date                                              title  \\\n",
      "0  2025-11-13  Repsol explores reverse merger for upstream un...   \n",
      "1  2025-11-13  Google to invest $40 billion in Texas data cen...   \n",
      "2  2025-11-13  Stocks Settle Mixed as Fed Comments Suggest a ...   \n",
      "3  2025-11-13  Samsung raised memory chip prices by up to 60%...   \n",
      "4  2025-11-13  Trump ready to exempt some food products from ...   \n",
      "\n",
      "           media                                               link  \n",
      "0  Yahoo Finance  https://finance.yahoo.com/news/repsol-explores...  \n",
      "1  Yahoo Finance  https://finance.yahoo.com/news/google-invest-4...  \n",
      "2  Yahoo Finance  https://finance.yahoo.com/news/stocks-settle-m...  \n",
      "3  Yahoo Finance  https://finance.yahoo.com/news/samsung-raised-...  \n",
      "4  Yahoo Finance  https://finance.yahoo.com/news/trump-ready-exe...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import glob\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm # é€²åº¦æ¢å¥—ä»¶\n",
    "\n",
    "\n",
    "# For colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# news_file_path = '/content/drive/MyDrive/fiisual/news_data2/*.csv'\n",
    "# model_name = \"/content/drive/MyDrive/fiisual/my_finbert_model_backup\"\n",
    "\n",
    "# 1. æº–å‚™å·¥ä½œ\n",
    "# å‡è¨­ä½ çš„è³‡æ–™åœ¨ df_newsï¼Œæ¬„ä½æœ‰ ['Date', 'Title']\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "project_root = current_dir.parent\n",
    "news_dir = project_root / 'data' / 'news_data'\n",
    "news_file_path = str(news_dir / '*.csv')\n",
    "\n",
    "# 2. æŠ“å–æ‰€æœ‰ CSV æª”æ¡ˆçš„æ¸…å–®\n",
    "all_files = glob.glob(news_file_path)\n",
    "print(f\"ğŸ“‚ æ‰¾åˆ° {len(all_files)} å€‹ CSV æª”æ¡ˆ\")\n",
    "\n",
    "# 3. è®€å–ä¸¦åˆä½µ\n",
    "df_list = []\n",
    "\n",
    "for filename in all_files:\n",
    "    try:\n",
    "        # è®€å–å–®å€‹ CSV\n",
    "        df = pd.read_csv(filename, index_col=None, header=0)\n",
    "        df_list.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ç„¡æ³•è®€å– {filename}: {e}\")\n",
    "\n",
    "# ä½¿ç”¨ concat ä¸€æ¬¡æ€§åˆä½µ\n",
    "if df_list:\n",
    "    df_news = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "    print(f\"âœ… åˆä½µå®Œæˆï¼ç¸½å…±æœ‰ {len(df_news)} ç­†è³‡æ–™\")\n",
    "\n",
    "    # 4. åŸºæœ¬æª¢æŸ¥\n",
    "    # å»é™¤é‡è¤‡ (ä»¥é˜²çˆ¬èŸ²æœ‰é‡ç–ŠæŠ“å–)\n",
    "    if 'title' in df_news.columns:\n",
    "        initial_count = len(df_news)\n",
    "        df_news = df_news.drop_duplicates(subset=['title'])\n",
    "        print(f\"ğŸ§¹ å»é™¤é‡è¤‡å¾Œå‰©é¤˜: {len(df_news)} ç­† (åˆªé™¤äº† {initial_count - len(df_news)} ç­†)\")\n",
    "\n",
    "    # æª¢æŸ¥æ¬„ä½\n",
    "    print(df_news.head())\n",
    "else:\n",
    "    print(\"âŒ æ²’æœ‰è®€å–åˆ°ä»»ä½•è³‡æ–™ï¼Œè«‹æª¢æŸ¥è·¯å¾‘æ˜¯å¦æ­£ç¢ºã€‚\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83e7b69",
   "metadata": {},
   "source": [
    "## 2. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b22ebcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æœªåµæ¸¬åˆ° GPUï¼Œå°‡ä½¿ç”¨ CPU åŸ·è¡Œ (é€Ÿåº¦è¼ƒæ…¢)\n",
      "ğŸš€ ä½¿ç”¨è£ç½®: cpu\n",
      "ğŸ§  é–‹å§‹é€²è¡Œæƒ…ç·’æ¨è«–...\n",
      "âœ… æ¨è«–å®Œæˆï¼å‰ 5 ç­†é è¦½ï¼š\n",
      "         date                                              title  \\\n",
      "0  2025-11-13  Repsol explores reverse merger for upstream un...   \n",
      "1  2025-11-13  Google to invest $40 billion in Texas data cen...   \n",
      "2  2025-11-13  Stocks Settle Mixed as Fed Comments Suggest a ...   \n",
      "3  2025-11-13  Samsung raised memory chip prices by up to 60%...   \n",
      "4  2025-11-13  Trump ready to exempt some food products from ...   \n",
      "\n",
      "   Sentiment_Label  Sentiment_Score  \n",
      "0                1         0.230534  \n",
      "1                1         0.219046  \n",
      "2                0        -0.862863  \n",
      "3                2         0.976522  \n",
      "4                1         0.256578  \n"
     ]
    }
   ],
   "source": [
    "model_dir = project_root / 'models' / 'finbert_sentiment'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "\n",
    "# å¦‚æœæœ‰ GPU å°±ç”¨ GPUï¼Œä¸ç„¶ç”¨ CPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"ğŸš€ ä½¿ç”¨ NVIDIA GPU åŠ é€Ÿ: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# å…¶æ¬¡æª¢æŸ¥ Mac Apple Silicon (MPS)\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"ğŸ ä½¿ç”¨ Apple Silicon (Metal) åŠ é€Ÿ\")\n",
    "\n",
    "# æœ€å¾Œä¸å¾—å·²æ‰ç”¨ CPU\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"âš ï¸ æœªåµæ¸¬åˆ° GPUï¼Œå°‡ä½¿ç”¨ CPU åŸ·è¡Œ (é€Ÿåº¦è¼ƒæ…¢)\")\n",
    "\n",
    "model.to(device)\n",
    "print(f\"ğŸš€ ä½¿ç”¨è£ç½®: {device}\")\n",
    "\n",
    "# 2. å®šç¾©æ¨è«–å‡½æ•¸ (æ”¯æ´ Batch)\n",
    "def predict_sentiment_label_batch(titles, batch_size=32):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "\n",
    "    # ä½¿ç”¨ tqdm é¡¯ç¤ºé€²åº¦æ¢ (å¦‚æœæ²’è£ tqdm å¯ä»¥æ‹¿æ‰é€™è¡Œï¼Œæ”¹ç”¨ä¸€èˆ¬ range)\n",
    "    for i in range(0, len(titles), batch_size):\n",
    "        batch = titles[i : i+batch_size]\n",
    "\n",
    "        # 1. Tokenize\n",
    "        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=64)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        # 2. Inference\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        # 3. è¨ˆç®—æ©Ÿç‡ (Softmax)\n",
    "        # outputs.logits å½¢ç‹€æ˜¯ [batch_size, 3] -> åˆ†åˆ¥å°æ‡‰ [Negative, Neutral, Positive]\n",
    "        probs = F.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "        # 4. å–æœ€å¤§å€¼çš„ç´¢å¼• (Argmax) -- é€™å°±æ˜¯é—œéµä¿®æ”¹ï¼\n",
    "        # æ‰¾å‡ºæ¯ä¸€åˆ—ä¸­æ©Ÿç‡æœ€å¤§çš„é‚£å€‹ index (0, 1, æˆ– 2)\n",
    "        batch_labels = torch.argmax(probs, dim=-1).cpu().numpy()\n",
    "\n",
    "        all_labels.extend(batch_labels)\n",
    "\n",
    "    return all_labels\n",
    "\n",
    "def predict_sentiment_batch(titles, batch_size=32):\n",
    "    model.eval()\n",
    "    scores = []\n",
    "\n",
    "    # ä½¿ç”¨ tqdm é¡¯ç¤ºé€²åº¦æ¢\n",
    "    for i in range(0, len(titles), batch_size):\n",
    "        batch = titles[i : i+batch_size]\n",
    "\n",
    "        # Tokenize\n",
    "        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=64)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        # Inference\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        # è¨ˆç®—æ©Ÿç‡ (Softmax)\n",
    "        probs = F.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "        # è¨ˆç®—åˆ†æ•¸: Positive(2) - Negative(0)\n",
    "        # FinBERT label order: [0: Negative, 1: Neutral, 2: Positive]\n",
    "        batch_scores = (probs[:, 2] - probs[:, 0]).cpu().numpy()\n",
    "        scores.extend(batch_scores)\n",
    "\n",
    "    return scores\n",
    "\n",
    "# 3. åŸ·è¡Œæ¨è«–\n",
    "print(\"ğŸ§  é–‹å§‹é€²è¡Œæƒ…ç·’æ¨è«–...\")\n",
    "# ç‚ºäº†é¿å…æ¨™é¡Œä¸æ˜¯å­—ä¸²æ ¼å¼å°è‡´å ±éŒ¯ï¼Œå…ˆè½‰å‹\n",
    "titles_list = df_news['title'].astype(str).tolist()\n",
    "df_news['Sentiment_Score'] = predict_sentiment_batch(titles_list)\n",
    "df_news['Sentiment_Label'] = predict_sentiment_label_batch(titles_list)\n",
    "\n",
    "print(\"âœ… æ¨è«–å®Œæˆï¼å‰ 5 ç­†é è¦½ï¼š\")\n",
    "print(df_news[['date', 'title', 'Sentiment_Label', 'Sentiment_Score']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80341cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".finbert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
